"""
Benchmark Visualization Charts
Generates professional graphs for RL vs Dynamic Allocation comparison
"""

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
import json
import os

# Set style
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.facecolor'] = '#1a1a2e'
plt.rcParams['axes.facecolor'] = '#16213e'
plt.rcParams['axes.edgecolor'] = '#0f3460'
plt.rcParams['text.color'] = '#e8e8e8'
plt.rcParams['axes.labelcolor'] = '#e8e8e8'
plt.rcParams['xtick.color'] = '#e8e8e8'
plt.rcParams['ytick.color'] = '#e8e8e8'
plt.rcParams['axes.titlecolor'] = '#e94560'
plt.rcParams['font.size'] = 11
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['figure.titlesize'] = 16


def create_latency_comparison_chart(save_path: str):
    """Create latency comparison bar chart"""
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    scenarios = ['Daily Pattern\n(Predictable Burst)', 'Random Bursts\n(Unpredictable)']
    spark_latency = [1453.8, 150.7]
    rl_latency = [80, 80]
    
    x = np.arange(len(scenarios))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, spark_latency, width, label='Spark Dynamic Allocation', 
                   color='#e94560', edgecolor='white', linewidth=1.5)
    bars2 = ax.bar(x + width/2, rl_latency, width, label='RL-based Scheduler',
                   color='#0f3460', edgecolor='white', linewidth=1.5)
    
    # Add value labels
    for bar, val in zip(bars1, spark_latency):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 30, 
                f'{val:.0f}ms', ha='center', va='bottom', fontsize=10, color='#e94560')
    
    for bar, val in zip(bars2, rl_latency):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 30,
                f'{val:.0f}ms', ha='center', va='bottom', fontsize=10, color='#4a90d9')
    
    ax.set_ylabel('Average Latency (ms)', fontsize=12)
    ax.set_title('üìä Average Latency: RL vs Spark Dynamic Allocation', fontsize=14, pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(scenarios)
    ax.legend(loc='upper right', facecolor='#1a1a2e', edgecolor='#0f3460')
    ax.set_ylim(0, max(spark_latency) * 1.2)
    
    # Add improvement annotations
    ax.annotate('94.5% ‚Üì', xy=(0, 80), xytext=(0, 500),
               arrowprops=dict(arrowstyle='->', color='#00ff00'), 
               fontsize=12, color='#00ff00', ha='center')
    ax.annotate('46.9% ‚Üì', xy=(1, 80), xytext=(1, 200),
               arrowprops=dict(arrowstyle='->', color='#00ff00'),
               fontsize=12, color='#00ff00', ha='center')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, facecolor='#1a1a2e', edgecolor='none')
    plt.close()
    print(f"‚úÖ Saved: {save_path}")


def create_sla_violations_chart(save_path: str):
    """Create SLA violations comparison"""
    
    fig, ax = plt.subplots(figsize=(8, 6))
    
    categories = ['Daily Pattern', 'Random Bursts']
    spark_violations = [54, 0]
    rl_violations = [0, 0]
    
    x = np.arange(len(categories))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, spark_violations, width, label='Spark', color='#e94560')
    bars2 = ax.bar(x + width/2, rl_violations, width, label='RL', color='#0f3460')
    
    # Add value labels
    for bar, val in zip(bars1, spark_violations):
        if val > 0:
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                   str(val), ha='center', va='bottom', fontsize=12, color='#e94560', fontweight='bold')
    
    for bar, val in zip(bars2, rl_violations):
        ax.text(bar.get_x() + bar.get_width()/2, 2,
               '0 ‚úì', ha='center', va='bottom', fontsize=12, color='#00ff00', fontweight='bold')
    
    ax.set_ylabel('SLA Violations', fontsize=12)
    ax.set_title('‚ö†Ô∏è SLA Violations: RL Prevents All During Bursts', fontsize=14, pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(categories)
    ax.legend(loc='upper right', facecolor='#1a1a2e', edgecolor='#0f3460')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, facecolor='#1a1a2e', edgecolor='none')
    plt.close()
    print(f"‚úÖ Saved: {save_path}")


def create_workload_timeline_chart(save_path: str):
    """Create workload timeline with scaling behavior"""
    
    fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)
    
    # Generate sample workload
    np.random.seed(42)
    time = np.arange(0, 240)
    
    workload = []
    for t in time:
        hour = (t / 10) % 24
        if 0 <= hour < 6:
            rate = 10
        elif 6 <= hour < 9:
            rate = 50 + (hour - 6) * 50
        elif 9 <= hour < 10:
            rate = 500  # BURST
        elif 10 <= hour < 17:
            rate = 150
        elif 17 <= hour < 18:
            rate = 300  # Evening spike
        else:
            rate = 50
        workload.append(rate)
    
    workload = np.array(workload)
    
    # Simulate Spark scaling (reactive, delayed)
    spark_executors = np.ones(240) * 2
    spark_backlog = np.zeros(240)
    pending = 0
    ready_at = -1
    backlog = 0
    
    for t in range(240):
        if pending > 0 and t >= ready_at:
            spark_executors[t:] = spark_executors[t] + pending
            pending = 0
        
        capacity = spark_executors[t] * 50
        backlog += max(0, workload[t] - capacity)
        spark_backlog[t] = backlog
        
        if backlog > 100 and pending == 0:
            pending = spark_executors[t]
            ready_at = t + 15  # 15 second delay!
    
    # RL scaling (proactive)
    rl_executors = np.ones(240) * 2
    
    for t in range(240):
        # Look ahead 10 seconds
        future = min(t + 10, 239)
        ideal = max(2, workload[future] / 50 + 1)
        rl_executors[t:] = min(50, ideal)
    
    # Plot 1: Workload and Executors
    ax1 = axes[0]
    ax1.fill_between(time, workload, alpha=0.3, color='#4a90d9', label='IoT Workload')
    ax1.plot(time, workload, color='#4a90d9', linewidth=2)
    
    ax1_twin = ax1.twinx()
    ax1_twin.plot(time, spark_executors, color='#e94560', linewidth=2, linestyle='--', label='Spark Executors')
    ax1_twin.plot(time, rl_executors, color='#00ff00', linewidth=2, label='RL Executors')
    
    ax1.set_ylabel('Message Rate (msg/s)', color='#4a90d9')
    ax1_twin.set_ylabel('Executors', color='#e94560')
    ax1.set_title('üìà Workload vs Executor Scaling: Reactive vs Proactive', fontsize=14, pad=20)
    
    # Add burst annotation
    ax1.axvspan(90, 100, alpha=0.3, color='red', label='9 AM Burst')
    ax1.text(95, 550, '9 AM\nBurst!', ha='center', fontsize=10, color='red')
    
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax1_twin.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', facecolor='#1a1a2e')
    
    # Plot 2: Backlog comparison
    ax2 = axes[1]
    ax2.fill_between(time, spark_backlog, alpha=0.5, color='#e94560', label='Spark Backlog')
    ax2.axhline(y=0, color='#00ff00', linewidth=2, linestyle='-', label='RL Backlog (‚âà0)')
    
    ax2.set_ylabel('Backlog (messages)')
    ax2.set_xlabel('Time (seconds) - 10s = 1 hour simulated')
    ax2.set_title('üìâ Backlog Accumulation: Spark Struggles During Bursts', fontsize=14, pad=20)
    ax2.legend(loc='upper right', facecolor='#1a1a2e')
    
    # Add annotation for the lag
    max_backlog_idx = np.argmax(spark_backlog)
    ax2.annotate(f'Peak: {int(spark_backlog[max_backlog_idx])} msgs', 
                xy=(max_backlog_idx, spark_backlog[max_backlog_idx]),
                xytext=(max_backlog_idx + 20, spark_backlog[max_backlog_idx] * 0.8),
                arrowprops=dict(arrowstyle='->', color='#e94560'),
                fontsize=10, color='#e94560')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, facecolor='#1a1a2e', edgecolor='none')
    plt.close()
    print(f"‚úÖ Saved: {save_path}")


def create_cost_comparison_chart(save_path: str):
    """Create cost comparison pie chart"""
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # Scenario 1: Daily Pattern
    ax1 = axes[0]
    sizes1 = [37.58, 18.88]
    labels1 = ['Spark\n$0.38', 'RL\n$0.19']
    colors1 = ['#e94560', '#0f3460']
    explode1 = (0.05, 0)
    
    ax1.pie(sizes1, explode=explode1, labels=labels1, colors=colors1, autopct='',
            shadow=True, startangle=90, textprops={'color': 'white', 'fontsize': 12})
    ax1.set_title('Daily Pattern\n(49.8% Cost Savings)', fontsize=12, color='#00ff00')
    
    # Scenario 2: Random Bursts  
    ax2 = axes[1]
    sizes2 = [9.54, 13.42]
    labels2 = ['Spark\n$0.10', 'RL\n$0.13']
    colors2 = ['#e94560', '#0f3460']
    explode2 = (0, 0.05)
    
    ax2.pie(sizes2, explode=explode2, labels=labels2, colors=colors2, autopct='',
            shadow=True, startangle=90, textprops={'color': 'white', 'fontsize': 12})
    ax2.set_title('Random Bursts\n(RL prioritizes latency)', fontsize=12, color='#ffc107')
    
    fig.suptitle('üí∞ Cost Comparison (in arbitrary units)', fontsize=14, y=1.02)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, facecolor='#1a1a2e', edgecolor='none', bbox_inches='tight')
    plt.close()
    print(f"‚úÖ Saved: {save_path}")


def create_summary_dashboard(save_path: str):
    """Create summary dashboard with all key metrics"""
    
    fig = plt.figure(figsize=(16, 12))
    
    # Title
    fig.suptitle('üöÄ RL vs Spark Dynamic Allocation: Complete Benchmark Results', 
                fontsize=18, fontweight='bold', y=0.98)
    
    # Create grid
    gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.3)
    
    # Metric 1: Latency Reduction
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.text(0.5, 0.7, '94.5%', fontsize=48, ha='center', va='center', 
            color='#00ff00', fontweight='bold', transform=ax1.transAxes)
    ax1.text(0.5, 0.3, 'Latency\nReduction', fontsize=14, ha='center', va='center',
            color='#e8e8e8', transform=ax1.transAxes)
    ax1.set_xlim(0, 1)
    ax1.set_ylim(0, 1)
    ax1.axis('off')
    
    # Metric 2: SLA Violations Prevented
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.text(0.5, 0.7, '54', fontsize=48, ha='center', va='center',
            color='#00ff00', fontweight='bold', transform=ax2.transAxes)
    ax2.text(0.5, 0.3, 'SLA Violations\nPrevented', fontsize=14, ha='center', va='center',
            color='#e8e8e8', transform=ax2.transAxes)
    ax2.set_xlim(0, 1)
    ax2.set_ylim(0, 1)
    ax2.axis('off')
    
    # Metric 3: Drop Rate Improvement
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.text(0.5, 0.7, '0%', fontsize=48, ha='center', va='center',
            color='#00ff00', fontweight='bold', transform=ax3.transAxes)
    ax3.text(0.5, 0.3, 'Message\nDrop Rate', fontsize=14, ha='center', va='center',
            color='#e8e8e8', transform=ax3.transAxes)
    ax3.set_xlim(0, 1)
    ax3.set_ylim(0, 1)
    ax3.axis('off')
    
    # Bar chart: Latency comparison
    ax4 = fig.add_subplot(gs[1, :2])
    scenarios = ['Daily Pattern', 'Random Bursts']
    spark = [1453.8, 150.7]
    rl = [80, 80]
    x = np.arange(len(scenarios))
    width = 0.35
    
    bars1 = ax4.bar(x - width/2, spark, width, label='Spark', color='#e94560')
    bars2 = ax4.bar(x + width/2, rl, width, label='RL', color='#0f3460')
    ax4.set_ylabel('Latency (ms)')
    ax4.set_title('Average Latency Comparison')
    ax4.set_xticks(x)
    ax4.set_xticklabels(scenarios)
    ax4.legend()
    
    # Key insight box
    ax5 = fig.add_subplot(gs[1, 2])
    insight_text = """
    KEY INSIGHT
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    RL pre-scales
    BEFORE bursts
    
    Spark reacts
    AFTER backlog
    
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    15s startup delay
    = 15s SLA violations
    """
    ax5.text(0.5, 0.5, insight_text, fontsize=11, ha='center', va='center',
            color='#e8e8e8', transform=ax5.transAxes, family='monospace',
            bbox=dict(boxstyle='round', facecolor='#0f3460', edgecolor='#00ff00'))
    ax5.axis('off')
    
    # Bottom: Thesis quote
    ax6 = fig.add_subplot(gs[2, :])
    quote = """
    "Although Spark's dynamic allocation can scale executors based on current backlog, 
    it relies on static heuristics. The RL-based scheduler learns workload patterns and 
    makes proactive, cost-aware scaling decisions, which is especially beneficial for 
    bursty IoT streaming workloads."
    """
    ax6.text(0.5, 0.5, quote, fontsize=12, ha='center', va='center',
            color='#ffc107', transform=ax6.transAxes, style='italic',
            wrap=True, bbox=dict(boxstyle='round', facecolor='#16213e', edgecolor='#ffc107'))
    ax6.axis('off')
    
    plt.savefig(save_path, dpi=150, facecolor='#1a1a2e', edgecolor='none', bbox_inches='tight')
    plt.close()
    print(f"‚úÖ Saved: {save_path}")


def main():
    """Generate all benchmark charts"""
    
    print("\n" + "="*60)
    print("üìä Generating Benchmark Visualization Charts")
    print("="*60 + "\n")
    
    # Create output directory
    output_dir = os.path.join(os.path.dirname(__file__), 'charts')
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate charts
    create_latency_comparison_chart(os.path.join(output_dir, 'latency_comparison.png'))
    create_sla_violations_chart(os.path.join(output_dir, 'sla_violations.png'))
    create_workload_timeline_chart(os.path.join(output_dir, 'workload_timeline.png'))
    create_cost_comparison_chart(os.path.join(output_dir, 'cost_comparison.png'))
    create_summary_dashboard(os.path.join(output_dir, 'summary_dashboard.png'))
    
    print(f"\n‚úÖ All charts saved to: {output_dir}/")
    print("\nGenerated files:")
    for f in os.listdir(output_dir):
        print(f"   üìà {f}")
    
    return output_dir


if __name__ == "__main__":
    main()
